{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Fill the Mask with T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 1.21k/1.21k [00:00<00:00, 3.70MB/s]\n",
      "spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 858kB/s]\n",
      "tokenizer.json: 100%|██████████| 1.39M/1.39M [00:00<00:00, 1.77MB/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\", low_cpu_mem_usage=True, torch_dtype=torch.bfloat16)                                                                                                  \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = \"Mr. Dursley was the director of a firm called <extra_id_0>, which made <extra_id_1>. He was a big, solid man with a bald head. Mrs. Dursley was thin and <extra_id_2> of neck, which came in very useful as she spent so much of her time <extra_id_3>. The Dursleys had a small son called Dudley and <extra_id_4>\"    \n",
    "#input_string = \"Hallo. Mein Name ist <extra_id_0> und ich wohne in <extra_id_1>. Das Wetter ist heute schön, deswegen werde ich <extra_id_2>.\"                                      \n",
    "#input_string = \"Learning a new language like English can be challenging, but <extra_id_0> helps to <extra_id_1> faster. Practice and <extra_id_2> every day will improve <extra_id_3> skills. Don't forget to <extra_id_4> new words regularly!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad><extra_id_0> the Dursleys<extra_id_1> him a great man<extra_id_2> had a bald head<extra_id_3> in the firm<extra_id_4> a son called Dudley. He was a great man with a bald head<extra_id_5> the Dursleys<extra_id_6> him a great man<extra_id_7> the Dursleys<extra_id_8> the Dursleys<extra_id_9> him a great man<extra_id_10> had a bald head<extra_id_11> had a bald head<extra_id_12> in the firm<extra_id_13> in the firm<extra_id_14> a son called Dudley<extra_id_15> the firm<extra_id_16> the firm<extra_id_17> the firm<extra_id_18> it<extra_id_19> the</s>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(input_string, return_tensors=\"pt\", add_special_tokens=False).input_ids\n",
    "\n",
    "outputs = model.generate(inputs, max_length=200)\n",
    "\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meine Schwester wohnt in Bayern und Ich fährt ein rotes Auto.\n",
      "Meine Schwester wohnt in Bayern und Meine fährt ein rotes Auto.\n",
      "Meine Schwester wohnt in Bayern und <extra_id_0> fährt ein rotes Auto.\n",
      "Meine Schwester wohnt in Bayern und Mein fährt ein rotes Auto.\n",
      "Meine Schwester wohnt in Bayern und Die fährt ein rotes Auto.\n",
      "Meine Schwester wohnt in Bayern und Das fährt ein rotes Auto.\n",
      "Meine Schwester wohnt in Bayern und  fährt ein rotes Auto.\n",
      "Meine Schwester wohnt in Bayern und Der fährt ein rotes Auto.\n",
      "Meine Schwester wohnt in Bayern und Nach fährt ein rotes Auto.\n",
      "{'Ich': tensor(-1.8359), 'Meine': tensor(-2.0625), '<extra_id_0>': tensor(-2.3125), 'Mein': tensor(-2.3438), 'Die': tensor(-3.0938), 'Das': tensor(-3.4375), '': tensor(-3.8125), 'Der': tensor(-4.), 'Nach': tensor(-4.2500)}\n"
     ]
    }
   ],
   "source": [
    "def get_target_scores(text, targets, t5_tokenizer, t5_model):\n",
    "  \"\"\"\n",
    "  A wrapper function for a mask fill-in with target words for (flan-)t5\n",
    "  Parameters:\n",
    "    text(String): The input text with <extra_id_0> as mask\n",
    "    targets(list): A list with target words\n",
    "    t5_tokenizer(T5Tokenizer): The loaded tokenizer\n",
    "    t5_model(T5ForConditionalGeneration): The loaded t5 model\n",
    "  \"\"\"\n",
    "  target_numbers = len(targets)\n",
    "  constrain_ids_list = []\n",
    "\n",
    "  # encode the target words\n",
    "  for target in targets:\n",
    "    encoded_target_ids = t5_tokenizer(target, add_special_tokens=False).input_ids\n",
    "    constrain_ids_list.append(encoded_target_ids)\n",
    "\n",
    "  # encode the input text\n",
    "  encoded = t5_tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='pt')\n",
    "  input_ids = encoded['input_ids']\n",
    "\n",
    "  # generate the outputs with the target as constrains\n",
    "  outputs = t5_model.generate(input_ids=input_ids,\n",
    "                          #force_words_ids=[constrain_ids_list],\n",
    "                          num_beams=target_numbers+5, num_return_sequences=target_numbers+5,\n",
    "                          return_dict_in_generate=True,\n",
    "                          output_scores=True,\n",
    "                          max_length=2)\n",
    "  \n",
    "  # calculate the mask position\n",
    "  _0_index = text.index('<extra_id_0>')\n",
    "  _result_prefix = text[:_0_index]\n",
    "  _result_suffix = text[_0_index+12:]  # 12 is the length of <extra_id_0>\n",
    "\n",
    "  result_dict = {}\n",
    "  # filter each output and save it into the result dictionary\n",
    "  for output_number, output in enumerate(outputs[\"sequences\"]):\n",
    "    _txt = t5_tokenizer.decode(output[1:], skip_special_tokens=False, clean_up_tokenization_spaces=False)\n",
    "\n",
    "   # if _txt in targets:\n",
    "    # save the target score\n",
    "    result_dict[_txt] = outputs[\"sequences_scores\"][output_number]\n",
    "    # complete text\n",
    "    print(_result_prefix + _txt + _result_suffix)\n",
    "\n",
    "  # return the aggregated result\n",
    "  return result_dict\n",
    "\n",
    "# test the function with this input text\n",
    "text = 'Meine Schwester wohnt in Bayern und <extra_id_0> fährt ein rotes Auto.' #'India is a <extra_id_0> of the world.'\n",
    "scores = get_target_scores(text, [\"part\", \"state\", \"country\", \"democracy\"], tokenizer, model)\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
